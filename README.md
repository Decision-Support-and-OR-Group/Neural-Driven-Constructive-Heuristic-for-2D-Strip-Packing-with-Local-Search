# Neural Driven Constructive Heuristic 2D Strip Packing with Local Search
## Description
Implementation of the algorithm described in the paper Kaleta,M. and Śliwiński, T.: "Improving Neural-Based Heuristics for 2D Strip Packing through Local Search in Heuristic Space".

This is a novel neural-driven constructive heuristic employing a population of simple feed-forward neural networks, which are trained using black-box optimization via the Covariance Matrix Adaptation Evolution Strategy (CMA-ES). The resulting neural network dynamically scores candidate placements within the constructive heuristic. Unlike conventional heuristics, the approach adapts to instance-specific characteristics without relying on predefined rules.
The algorithm is extended by integrating a local search strategy that explores the space of heuristics, encoded as neural network weights, rather than the solution space.

We consider the two-dimensional orthogonal rectangular strip packing problem (2D-SPP), which involves arranging a set of rectangular items on a strip of fixed width W and unbounded (infinite) length. 
Items may be rotated by 90 degrees.

We assume a weak heterogeneity among the items, meaning that items can be grouped into relatively few types compared to the total number of items.

## Testing data

Two types of synthetic date were used for training and testing: 
* generated by the  2DCPackGen, a tool for generating two-dimensional rectangular cutting and packing problems (https://doi.org/10.1016/j.ejor.2014.02.059), and 
* real-live logistic data sets, that can be generated by our tool with proper command line options

Test data used throughout the article can be found in the `test_data` directory, and data used for neural network training and validation can be found in the `train_data` directory.

Together with the files generated by the 2DCPackGen we also share the parameter files used for data generation. 

## Functionality

The program allows:
* generating fully random sythetic data of the real-life logistic type 
* training the neural network using previously generated data of both types 
* testing - solving the test problems using previously trained neural network 

## Installation

The program uses CMAES library, which should be installed beforehand.

The following installation was tested in Ubuntu 24.04.

```bash
sudo apt-get install git build-essential autoconf automake make libtool libgoogle-glog-dev libgflags-dev libeigen3-dev ninja-build libeigen3-dev git gdb valgrind clang-tidy libboost-all-dev nlohmann-json3-dev libsfml-dev

# install libcmaes
git clone https://github.com/CMA-ES/libcmaes.git

# for cmaes do not use cmake, instead compile with basic options enabled
cd libcmaes
./autogen.sh
echo "#define CMAES_EXPORT" > include/libcmaes/cmaes_export.h
./configure
make

# download and install the program
git clone https://github.com/Decision-Support-and-OR-Group/Neural-Driven-Constructive-Heuristic-for-2D-Strip-Packing-with-Local-Search.git

cd Neural-Driven-Constructive-Heuristic-for-2D-Strip-Packing-with-Local-Search

# if needed, modify CMakeLists.txt to point to libcmaes directories

mkdir build
cd build
cmake -DCMAKE_BUILD_TYPE=Release -G "Ninja" ..
# cmake -DCMAKE_BUILD_TYPE=Debug -G "Ninja" .. # for debuggable (slow) version
cmake --build .
cd ..
```


### Program usage
Executing:
```bash
./nd-ch-sp --help
```

results in the following description of the basic program usage:
```
Usage: nd-ch-sp [mode] [options]

Global Options:
  --generate_logistic   Mode: Generate logistic data
  --train               Mode: Train neural network
  --test                Mode: Test/Solve problems
  -h [ --help ]         Show help

Generation Options (--generate_logistic):
  --output_file arg     File path to store generated training/validation or 
                        test problems
  --strip_width arg     Strip width
  --T arg               Number of different item types
  --dt_min arg          Minimum number of items of each type
  --dt_max arg          Maximum number of items of each type
  --dim arg             Chosen size category: small | medium | large | mixed
  --set_size arg        Number of generated problems.
  --seed arg (=1)       Generator's seed.

Training Options (--train):
  --output_dir arg            Directory to store output data including trained 
                              NN.
  --input_file arg            File with training/validation problems.
  --val_set_size arg (=10000) Number of validation problems to take from the 
                              'file'
  --layer1 arg (=32)          Neural networks first hiden layer size
  --layer2 arg (=16)          Neural networks second hiden layer size
  --batch_size arg (=100)     Training batch size
  --population arg (=192)     CMAES population size
  --max_evals arg (=500000)   Maximum number of black box function evaluations 
                              (number of evaluated batches)
  --sigma arg (=0.400000006)  CMAES sigma parameter
  --seed arg (=1)             CMAES initial seed

Testing Options (--test):
  --output_dir arg           Directory to store results
  --input_file arg           File with the problems to solve
  --training_output_dir arg  Directory with saved NN weights
  --time_limit arg (=60)     Maximum testing time per problem
  --population arg (=192)    CMAES population size
  --max_evals arg (=500000)  Maximum number of black box function evaluations
  --sigma arg (=0.400000006) CMAES sigma parameter
  --seed arg (=1)            CMAES initial seed
  --solution                 If specified, the solution will be written to the 
                             output_dir
  --graphics                 If specified, the solution image will be generated
                             for each problem
```

### Examples
Typical workflow with the program looks as follows:

1. Generate random synthetic training problems of the real-life logistic type and save them into `test_dir/gen_file.txt` file.
```
./nd-ch-sp --generate_logistic --output_file=test_dir/training_instances.txt --strip_width=1200 --T=10 --dt_min=1 --dt_max=10 --dim=small --set_size=500000 --seed=1
```

2. Train new network on generated problems. Save the network in the `test_dir` directory.
```
./nd-ch-sp --train --output_dir=test_dir --input_file=test_dir/training_instances.txt --val_set_size=10000 --layer1=32 --layer2=16 --batch_size=100 --population=192 --max_evals=500000 --sigma=0.4 --seed=1
```

3. Generate smaller set of test problems and save them into `test_dir/test_instances.txt` file. Important is, that most options, with exception to 'seed' are the same as in the training set.
```
./nd-ch-sp --generate_logistic --output_file=test_dir/test_instances.txt --strip_width=1200 --T=10 --dt_min=1 --dt_max=10 --dim=small --set_size=10 --seed=10000
```

4. Test the constructive heuristic utilizing previously trained network in the `test_dir` directory on a set of test problems in the `test_dir/test_instances.txt` file. Store results in the `test_dir` directory.
```
./nd-ch-sp --test --output_dir=test_dir --input_file=test_dir/test_instances.txt --training_output_dir=test_dir --time_limit=60 --population=192 --max_evals=50000000 --sigma=0.4 --seed=1 --solution --graphics
```

